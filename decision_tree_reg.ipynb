{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTreeReg:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, max_leafs=20, bins=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs\n",
    "        self.leafs_cnt = 0  # Добавляем переменную для хранения кол-ва листьев\n",
    "        self.tree = None  # Здесь будем хранить дерево, которое создадим\n",
    "        self.bins = bins  # Количество бинов для гистограмм\n",
    "        self.fi = {}  # Важность фичей\n",
    "        \n",
    "    def __str__(self):\n",
    "        params = vars(self) # Получаем все атрибуты экземпляра как словарь\n",
    "        params_str = ', '.join(f\"{key}={value}\" for key, value in params.items())\n",
    "        return f\"MyTreeReg class: {params_str}\"\n",
    "    \n",
    "    def mse(self, y):\n",
    "        return np.mean((y - np.mean(y)) ** 2)\n",
    "\n",
    "    def get_best_split(self, X, y):\n",
    "        best_gain = -np.inf  # Изначально прирост установлен как отрицательная бесконечность\n",
    "        best_split = {'col_name': None, 'split_value': None, 'gain': None}  # Инициализируем структуру для хранения лучшего сплита\n",
    "\n",
    "        current_mse = self.mse(y)  # Текущий MSE для всего набора данных\n",
    "\n",
    "        # Проходим по всем колонкам\n",
    "        for col in X.columns:\n",
    "            unique_values = np.sort(X[col].unique())  # Получаем уникальные отсортированные значения в колонке\n",
    "            \n",
    "             # Если количество уникальных значений меньше или равно bins, используем их\n",
    "            if self.bins is None or len(unique_values) <= self.bins:\n",
    "                split_candidates = (unique_values[:-1] + unique_values[1:]) / 2\n",
    "            else:\n",
    "                # Если больше, строим гистограмму\n",
    "                _, bin_edges = np.histogram(X[col], bins=self.bins)\n",
    "                split_candidates = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "            # Проходим по всем уникальным значениям (кроме последнего), чтобы выбрать разделитель\n",
    "            for split_value in split_candidates:\n",
    "                # Разделяем данные на две части\n",
    "                left_mask = X[col] <= split_value\n",
    "                right_mask = X[col] > split_value\n",
    "\n",
    "                # Проверяем, что обе части содержат достаточно данных (учитываем min_samples_split)\n",
    "                if left_mask.sum() < self.min_samples_split or right_mask.sum() < self.min_samples_split:\n",
    "                    continue\n",
    "\n",
    "                # Вычисляем MSE для каждой части\n",
    "                left_mse = self.mse(y[left_mask])\n",
    "                right_mse = self.mse(y[right_mask])\n",
    "\n",
    "                # Вычисляем взвешенное MSE после разделения\n",
    "                weighted_mse = (left_mask.sum() * left_mse + right_mask.sum() * right_mse) / len(y)\n",
    "\n",
    "                # Вычисляем прирост (разницу) MSE\n",
    "                gain = current_mse - weighted_mse\n",
    "\n",
    "                # Если прирост больше текущего лучшего, обновляем лучший сплит\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_split['col_name'] = col\n",
    "                    best_split['split_value'] = split_value\n",
    "                    best_split['gain'] = gain\n",
    "\n",
    "        return best_split\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.leafs_cnt = 0  # Сбрасываем счетчик листьев перед началом обучения\n",
    "        self.fi = {col: 0 for col in X.columns}  # Инициализируем важность фичей нулями\n",
    "        self.tree = self._grow_tree(X, y, depth=0)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Останавливаем рост дерева при достижении условий\n",
    "        if depth >= self.max_depth or n_samples < self.min_samples_split or self.leafs_cnt >= self.max_leafs:\n",
    "            self.leafs_cnt += 1\n",
    "            return np.mean(y)  # Возвращаем среднее значение как результат для листа\n",
    "\n",
    "        # Ищем лучший сплит\n",
    "        best_split = self.get_best_split(X, y)\n",
    "\n",
    "        if best_split['gain'] is None or best_split['gain'] == 0:\n",
    "            self.leafs_cnt += 1\n",
    "            return np.mean(y)\n",
    "        \n",
    "        # Обновляем важность фичи\n",
    "        self.fi[best_split['col_name']] += best_split['gain']\n",
    "\n",
    "        # Разделяем данные по лучшему сплиту\n",
    "        left_mask = X[best_split['col_name']] <= best_split['split_value']\n",
    "        right_mask = X[best_split['col_name']] > best_split['split_value']\n",
    "\n",
    "        # Рекурсивно строим поддеревья\n",
    "        left_tree = self._grow_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_tree = self._grow_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "\n",
    "        # Возвращаем узел дерева\n",
    "        return {\n",
    "            'split_feature': best_split['col_name'],\n",
    "            'split_value': best_split['split_value'],\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "        \n",
    "    def feature_importances(self):\n",
    "        return self.fi\n",
    "\n",
    "    def print_tree(self, tree=None, depth=0):\n",
    "        if tree is None:\n",
    "            tree = self.tree\n",
    "\n",
    "        # Если это лист, выводим его значение\n",
    "        if not isinstance(tree, dict):\n",
    "            print(f\"{' ' * depth * 4}Leaf: {tree:.2f}\")\n",
    "            return\n",
    "\n",
    "        # Иначе выводим сплит узел и рекурсивно отображаем поддеревья\n",
    "        print(f\"{' ' * depth * 4}Node: [Feature: {tree['split_feature']}, Split Value: {tree['split_value']:.2f}]\")\n",
    "        self.print_tree(tree['left'], depth + 1)\n",
    "        self.print_tree(tree['right'], depth + 1)\n",
    "        \n",
    "    def predict_row(self, tree, row):\n",
    "        # Рекурсивная функция для предсказания значения по одному ряду\n",
    "        # Если это лист, возвращаем значение листа\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        \n",
    "        # Идем по дереву в зависимости от значения признака\n",
    "        if row[tree['split_feature']] <= tree['split_value']:\n",
    "            return self.predict_row(tree['left'], row)\n",
    "        else:\n",
    "            return self.predict_row(tree['right'], row)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Метод для предсказания на основе обученного дерева\n",
    "        return [self.predict_row(self.tree, row) for _, row in X.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Важность фичей для первого набора данных: {'feature_0': 7201.791960173448, 'feature_1': 5307.428716540061}\n",
      "\n",
      "Важность фичей для второго набора данных: {'feature_0': 3048.962741935009, 'feature_1': 10359.538573743625, 'feature_2': 7317.395889800144}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Тестирование важности фичей\n",
    "X1, y1 = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)\n",
    "X1 = pd.DataFrame(X1, columns=[f'feature_{i}' for i in range(X1.shape[1])])\n",
    "y1 = pd.Series(y1)\n",
    "\n",
    "X2, y2 = make_regression(n_samples=150, n_features=3, noise=0.5, random_state=24)\n",
    "X2 = pd.DataFrame(X2, columns=[f'feature_{i}' for i in range(X2.shape[1])])\n",
    "y2 = pd.Series(y2)\n",
    "\n",
    "tree = MyTreeReg(max_depth=5, min_samples_split=2, max_leafs=10, bins=5)\n",
    "\n",
    "tree.fit(X1, y1)\n",
    "feature_importances_1 = tree.feature_importances()\n",
    "print(f\"Важность фичей для первого набора данных: {feature_importances_1}\\n\")\n",
    "\n",
    "tree.fit(X2, y2)\n",
    "feature_importances_2 = tree.feature_importances()\n",
    "print(f\"Важность фичей для второго набора данных: {feature_importances_2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сумма предсказаний для первого набора данных: -761.4847620370264\n",
      "\n",
      "Сумма предсказаний для второго набора данных: -867.3195994201674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Тестирование гистограмм\n",
    "X1, y1 = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)\n",
    "X1 = pd.DataFrame(X1, columns=[f'feature_{i}' for i in range(X1.shape[1])])\n",
    "y1 = pd.Series(y1)\n",
    "\n",
    "X2, y2 = make_regression(n_samples=150, n_features=3, noise=0.5, random_state=24)\n",
    "X2 = pd.DataFrame(X2, columns=[f'feature_{i}' for i in range(X2.shape[1])])\n",
    "y2 = pd.Series(y2)\n",
    "\n",
    "tree = MyTreeReg(max_depth=5, min_samples_split=2, max_leafs=10, bins=5)\n",
    "\n",
    "tree.fit(X1, y1)\n",
    "predictions_1 = tree.predict(X1)\n",
    "sum_predictions_1 = sum(predictions_1)\n",
    "print(f\"Сумма предсказаний для первого набора данных: {sum_predictions_1}\\n\")\n",
    "\n",
    "tree.fit(X2, y2)\n",
    "predictions_2 = tree.predict(X2)\n",
    "sum_predictions_2 = sum(predictions_2)\n",
    "print(f\"Сумма предсказаний для второго набора данных: {sum_predictions_2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сумма предсказаний для первого набора данных: -761.4847620370272\n",
      "\n",
      "Сумма предсказаний для второго набора данных: -867.3195994201674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Тестирование предсказания\n",
    "X1, y1 = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)\n",
    "X1 = pd.DataFrame(X1, columns=[f'feature_{i}' for i in range(X1.shape[1])])\n",
    "y1 = pd.Series(y1)\n",
    "\n",
    "X2, y2 = make_regression(n_samples=150, n_features=3, noise=0.5, random_state=24)\n",
    "X2 = pd.DataFrame(X2, columns=[f'feature_{i}' for i in range(X2.shape[1])])\n",
    "y2 = pd.Series(y2)\n",
    "\n",
    "# Создаем экземпляр класса MyTreeReg\n",
    "tree = MyTreeReg(max_depth=5, min_samples_split=2, max_leafs=10)\n",
    "\n",
    "\n",
    "tree.fit(X1, y1)\n",
    "predictions_1 = tree.predict(X1)\n",
    "sum_predictions_1 = sum(predictions_1)\n",
    "print(f\"Сумма предсказаний для первого набора данных: {sum_predictions_1}\\n\")\n",
    "\n",
    "\n",
    "tree.fit(X2, y2)\n",
    "predictions_2 = tree.predict(X2)\n",
    "sum_predictions_2 = sum(predictions_2)\n",
    "print(f\"Сумма предсказаний для второго набора данных: {sum_predictions_2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1:\n",
      "Количество листьев для первого набора данных: 13\n",
      "\n",
      "Dataset 2:\n",
      "Количество листьев для второго набора данных: 12\n"
     ]
    }
   ],
   "source": [
    "X1, y1 = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)\n",
    "X1 = pd.DataFrame(X1, columns=[f'feature_{i}' for i in range(X1.shape[1])])\n",
    "y1 = pd.Series(y1)\n",
    "\n",
    "X2, y2 = make_regression(n_samples=120, n_features=5, noise=0.5, random_state=24)\n",
    "X2 = pd.DataFrame(X2, columns=[f'feature_{i}' for i in range(X2.shape[1])])\n",
    "y2 = pd.Series(y2)\n",
    "\n",
    "tree = MyTreeReg(max_depth=5, min_samples_split=2, max_leafs=10)\n",
    "\n",
    "# Обучение на первом наборе данных\n",
    "tree.fit(X1, y1)\n",
    "print(\"Dataset 1:\")\n",
    "print(f\"Количество листьев для первого набора данных: {tree.leafs_cnt}\\n\")\n",
    "\n",
    "# Обучение на втором наборе данных\n",
    "tree.fit(X2, y2)\n",
    "print(\"Dataset 2:\")\n",
    "print(f\"Количество листьев для второго набора данных: {tree.leafs_cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best split: Feature = feature_1, Split Value = 0.24665448467044643, Gain = 4243.420812246212\n",
      "\n",
      "Best split: Feature = feature_2, Split Value = 0.28855607239980435, Gain = 5282.24536637628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Тестирование лучшего сплита\n",
    "X1, y1 = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)\n",
    "X2, y2 = make_regression(n_samples=150, n_features=3, noise=10, random_state=42)\n",
    "\n",
    "# Преобразуем данные в pandas DataFrame и Series\n",
    "X1 = pd.DataFrame(X1, columns=[f'feature_{i}' for i in range(X1.shape[1])])\n",
    "y1 = pd.Series(y1)\n",
    "X2 = pd.DataFrame(X2, columns=[f'feature_{i}' for i in range(X2.shape[1])])\n",
    "y2 = pd.Series(y2)\n",
    "\n",
    "# Создаем экземпляр класса MyTreeReg\n",
    "tree = MyTreeReg(max_depth=5, min_samples_split=2, max_leafs=20)\n",
    "\n",
    "# Датасет 1\n",
    "best_split_1 = tree.get_best_split(X1, y1)\n",
    "print(f\"Best split: Feature = {best_split_1['col_name']}, Split Value = {best_split_1['split_value']}, Gain = {best_split_1['gain']}\\n\")\n",
    "\n",
    "# Датасет 2\n",
    "best_split_2 = tree.get_best_split(X2, y2)\n",
    "print(f\"Best split: Feature = {best_split_2['col_name']}, Split Value = {best_split_2['split_value']}, Gain = {best_split_2['gain']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyTreeReg class: max_depth=5, min_samples_split=2, max_leafs=20\n",
      "MyTreeReg class: max_depth=10, min_samples_split=2, max_leafs=30\n",
      "MyTreeReg class: max_depth=5, min_samples_split=15, max_leafs=25\n"
     ]
    }
   ],
   "source": [
    "# Тестирование класса\n",
    "tree1 = MyTreeReg()\n",
    "tree2 = MyTreeReg(max_depth = 10, max_leafs = 30)\n",
    "tree3 = MyTreeReg(max_leafs = 25, min_samples_split = 15)\n",
    "\n",
    "# Проверка\n",
    "print(tree1)\n",
    "print(tree2)\n",
    "print(tree3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
