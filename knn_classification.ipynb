{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKNNClf:\n",
    "    def __init__(self, k=3, metric='euclidean', weight='uniform'):\n",
    "        # Сохраняем параметр k внутри экземпляра\n",
    "        self.k = k\n",
    "        # Инициализация переменной train_size\n",
    "        self.train_size = None\n",
    "        # Инициализация переменных для хранения тренировочных данных\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.metric = metric\n",
    "        self.weight = weight\n",
    "\n",
    "    def __str__(self):\n",
    "        # Возвращаем строку в требуемом формате\n",
    "        return f\"MyKNNClf class: k={self.k}\"\n",
    "    \n",
    "      # Метод обучения\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        # Сохраняем X и y внутри объекта класса\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        # Записываем размер тренировочной выборки (количество строк, столбцов)\n",
    "        self.train_size = X.shape  # shape возвращает кортеж (строки, столбцы)\n",
    "        \n",
    "    # Вычисление расстояния в зависимости от метрики\n",
    "    def _compute_distance(self, row1, row2):\n",
    "        if self.metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((row1 - row2) ** 2))\n",
    "        elif self.metric == 'chebyshev':\n",
    "            return np.max(np.abs(row1 - row2))\n",
    "        elif self.metric == 'manhattan':\n",
    "            return np.sum(np.abs(row1 - row2))\n",
    "        elif self.metric == 'cosine':\n",
    "            dot_product = np.dot(row1, row2)\n",
    "            norm1 = np.linalg.norm(row1)\n",
    "            norm2 = np.linalg.norm(row2)\n",
    "            return 1 - (dot_product / (norm1 * norm2))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric: {self.metric}\")\n",
    "        \n",
    "    # # Метод для вычисления Евклидова расстояния\n",
    "    # def _euclidean_distance(self, row1, row2):\n",
    "    #     return np.sqrt(np.sum((row1 - row2) ** 2))\n",
    "    \n",
    "     # Вычисление весов в зависимости от параметра weight\n",
    "    def _compute_weights(self, distances):\n",
    "        if self.weight == 'uniform':\n",
    "            return np.ones(len(distances))  # Все веса одинаковые\n",
    "        elif self.weight == 'rank':\n",
    "            # Вес обратно пропорционален рангу (месту в сортированном списке)\n",
    "            return 1 / (np.arange(1, len(distances) + 1))\n",
    "        elif self.weight == 'distance':\n",
    "            # Вес обратно пропорционален расстоянию (если расстояние равно 0, то вес задаем большим значением)\n",
    "            distances = np.array(distances)\n",
    "            with np.errstate(divide='ignore'):  # Игнорируем деление на 0\n",
    "                weights = 1 / distances\n",
    "                weights[distances == 0] = np.inf  # Если расстояние равно нулю, вес -> бесконечность\n",
    "            return weights\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown weight: {self.weight}\")\n",
    "\n",
    "     # Метод для предсказания классов\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        predictions = []\n",
    "        \n",
    "        for _, test_row in X.iterrows():\n",
    "            distances = []\n",
    "            for _, train_row in self.X_train.iterrows():\n",
    "                dist = self._compute_distance(test_row, train_row)\n",
    "                distances.append(dist)\n",
    "            \n",
    "            # Находим индексы k ближайших соседей\n",
    "            nearest_neighbors_indices = np.argsort(distances)[:self.k]\n",
    "            nearest_neighbors_classes = self.y_train.iloc[nearest_neighbors_indices]\n",
    "            nearest_distances = [distances[i] for i in nearest_neighbors_indices]\n",
    "\n",
    "            # Если вес 'uniform', то используем обычную моду\n",
    "            if self.weight == 'uniform':\n",
    "                most_common_class = Counter(nearest_neighbors_classes).most_common(1)[0][0]\n",
    "            else:\n",
    "                # Иначе вычисляем веса\n",
    "                weights = self._compute_weights(nearest_distances)\n",
    "                weighted_class_counts = Counter()\n",
    "                for weight, neighbor_class in zip(weights, nearest_neighbors_classes):\n",
    "                    weighted_class_counts[neighbor_class] += weight\n",
    "                \n",
    "                # Выбираем класс с наибольшим суммарным весом\n",
    "                most_common_class = weighted_class_counts.most_common(1)[0][0]\n",
    "\n",
    "            predictions.append(most_common_class)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    # Метод для предсказания вероятностей\n",
    "    def predict_proba(self, X: pd.DataFrame):\n",
    "        probabilities = []\n",
    "        \n",
    "        for _, test_row in X.iterrows():\n",
    "            distances = []\n",
    "            for _, train_row in self.X_train.iterrows():\n",
    "                dist = self._compute_distance(test_row, train_row)\n",
    "                distances.append(dist)\n",
    "            \n",
    "            # Находим индексы k ближайших соседей\n",
    "            nearest_neighbors_indices = np.argsort(distances)[:self.k]\n",
    "            nearest_neighbors_classes = self.y_train.iloc[nearest_neighbors_indices]\n",
    "            nearest_distances = [distances[i] for i in nearest_neighbors_indices]\n",
    "\n",
    "            # Если вес 'uniform', вероятность для класса 1 это доля соседей класса 1\n",
    "            if self.weight == 'uniform':\n",
    "                class_1_count = np.sum(nearest_neighbors_classes == 1)\n",
    "                probability_class_1 = class_1_count / self.k\n",
    "            else:\n",
    "                # Иначе вычисляем веса\n",
    "                weights = self._compute_weights(nearest_distances)\n",
    "                weighted_class_1_sum = sum(w for w, cls in zip(weights, nearest_neighbors_classes) if cls == 1)\n",
    "                total_weight = sum(weights)\n",
    "                probability_class_1 = weighted_class_1_sum / total_weight\n",
    "            \n",
    "            probabilities.append(probability_class_1)\n",
    "        \n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Output: (100, 49.7)\n"
     ]
    }
   ],
   "source": [
    "# Тестирование Взвешенный KNN\n",
    "def weighted_knn(k_value, metric_type, weight_type):\n",
    "    # Генерация данных для бинарной классификации\n",
    "    X, y = make_classification(n_samples=100, n_features=5, n_informative=3, n_classes=2, random_state=42)\n",
    "    \n",
    "    # Преобразуем в pandas DataFrame и Series\n",
    "    X_df = pd.DataFrame(X)\n",
    "    y_series = pd.Series(y)\n",
    "    \n",
    "    # Создаем и обучаем модель с указанной метрикой и весами\n",
    "    knn = MyKNNClf(k=k_value, metric=metric_type, weight=weight_type)\n",
    "    knn.fit(X_df, y_series)\n",
    "    \n",
    "    # Выполняем предсказание и предсказание вероятностей\n",
    "    predictions = knn.predict(X_df)\n",
    "    probabilities = knn.predict_proba(X_df)\n",
    "    \n",
    "    # Возвращаем количество предсказаний и сумму вероятностей\n",
    "    return len(predictions), sum(probabilities)\n",
    "\n",
    "# Пример вызова теста\n",
    "weight_type = 'rank'  # или 'distance'\n",
    "predictions_count, probabilities_sum = weighted_knn(k_value=3, metric_type='euclidean', weight_type=weight_type)\n",
    "print(f\"Sample Output: ({predictions_count}, {probabilities_sum:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Output: (100, 49.3)\n"
     ]
    }
   ],
   "source": [
    "# Тестирование метрик\n",
    "def test_metric(k_value, metric_type):\n",
    "    # Генерация данных для бинарной классификации\n",
    "    X, y = make_classification(n_samples=100, n_features=5, n_informative=3, n_classes=2, random_state=42)\n",
    "    \n",
    "    # Преобразуем в pandas DataFrame и Series\n",
    "    X_df = pd.DataFrame(X)\n",
    "    y_series = pd.Series(y)\n",
    "    \n",
    "    # Создаем и обучаем модель с указанной метрикой\n",
    "    knn = MyKNNClf(k=k_value, metric=metric_type)\n",
    "    knn.fit(X_df, y_series)\n",
    "    \n",
    "    # Выполняем предсказание и предсказание вероятностей\n",
    "    predictions = knn.predict(X_df)\n",
    "    probabilities = knn.predict_proba(X_df)\n",
    "    \n",
    "    # Возвращаем количество предсказаний и сумму вероятностей\n",
    "    return len(predictions), sum(probabilities)\n",
    "\n",
    "# Пример вызова теста\n",
    "metric_type = 'euclidean'\n",
    "predictions_count, probabilities_sum = test_metric(k_value=3, metric_type=metric_type)\n",
    "print(f\"Sample Output: ({predictions_count}, {probabilities_sum:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Output: (100, 49.33333333333332)\n"
     ]
    }
   ],
   "source": [
    "# Тестирование предсказания\n",
    "def test_knn(k_value):\n",
    "    # Генерация данных для бинарной классификации\n",
    "    X, y = make_classification(n_samples=100, n_features=5, n_informative=3, n_classes=2, random_state=42)\n",
    "    \n",
    "    # Преобразуем в pandas DataFrame и Series\n",
    "    X_df = pd.DataFrame(X)\n",
    "    y_series = pd.Series(y)\n",
    "    \n",
    "    # Создаем и обучаем модель\n",
    "    knn = MyKNNClf(k=k_value)\n",
    "    knn.fit(X_df, y_series)\n",
    "    \n",
    "    # Выполняем предсказание и предсказание вероятностей\n",
    "    predictions = knn.predict(X_df)\n",
    "    probabilities = knn.predict_proba(X_df)\n",
    "    \n",
    "    # Возвращаем количество предсказаний и сумму вероятностей\n",
    "    return len(predictions), sum(probabilities)\n",
    "\n",
    "# Пример вызова теста\n",
    "k_value = 3\n",
    "predictions_count, probabilities_sum = test_knn(k_value)\n",
    "print(f\"Sample Output: ({predictions_count}, {probabilities_sum})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1:\n",
      "Train size: (50, 5)\n",
      "----------------------------------------\n",
      "Test 2:\n",
      "Train size: (100, 10)\n",
      "----------------------------------------\n",
      "Test 3:\n",
      "Train size: (200, 20)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Тестирование обучения\n",
    "def test_knn_with_datasets():\n",
    "    # Список параметров для тестов\n",
    "    test_params = [\n",
    "        {\"n_samples\": 50, \"n_features\": 5, \"n_informative\": 2},\n",
    "        {\"n_samples\": 100, \"n_features\": 10, \"n_informative\": 5},\n",
    "        {\"n_samples\": 200, \"n_features\": 20, \"n_informative\": 10}\n",
    "    ]\n",
    "\n",
    "    # Создаем объект KNN\n",
    "    knn = MyKNNClf()\n",
    "\n",
    "    # Проходим по каждому набору параметров\n",
    "    for idx, params in enumerate(test_params):\n",
    "        # Генерация данных\n",
    "        X, y = make_classification(n_samples=params['n_samples'],\n",
    "                                   n_features=params['n_features'],\n",
    "                                   n_informative=params['n_informative'],\n",
    "                                   random_state=42)\n",
    "\n",
    "        # Преобразование в pandas DataFrame и Series\n",
    "        X_df = pd.DataFrame(X)\n",
    "        y_series = pd.Series(y)\n",
    "\n",
    "        # Обучение модели\n",
    "        knn.fit(X_df, y_series)\n",
    "\n",
    "        # Печать результата для каждого набора данных\n",
    "        print(f\"Test {idx + 1}:\")\n",
    "        print(f\"Train size: {knn.train_size}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "test_knn_with_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyKNNClf class: k=3\n",
      "MyKNNClf class: k=5\n",
      "MyKNNClf class: k=10\n"
     ]
    }
   ],
   "source": [
    "# Пример использования вызова класса\n",
    "knn1 = MyKNNClf()\n",
    "knn2 = MyKNNClf(5)\n",
    "knn3 = MyKNNClf(10)\n",
    "\n",
    "# Проверка\n",
    "print(knn1)\n",
    "print(knn2)\n",
    "print(knn3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
