{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from forest_reg import MyForestReg  # Импорт дерева\n",
    "from sklearn.datasets import make_regression\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBoostReg:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators=10,\n",
    "        max_depth=5,\n",
    "        min_samples_split=2,\n",
    "        max_leafs=20,\n",
    "        bins=None,\n",
    "        loss=\"MSE\",  # Добавлен параметр loss\n",
    "        metric=None,  # Метрика для оценки модели\n",
    "        max_features=0.5, #доля фичей\n",
    "        max_samples=0.5, #доля семплом\n",
    "        random_state=42,\n",
    "        learning_rate=0.1,\n",
    "        reg=0.1  # Новый параметр регуляризации\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs\n",
    "        self.bins = bins\n",
    "        self.pred_0 = None  # Изначальное предсказание (среднее по таргету)\n",
    "        self.trees = []     # Список для хранения обученных деревьев\n",
    "        self.loss = loss\n",
    "        self.metric = metric\n",
    "        self.best_score = None  # Хранение лучшего значения метрики\n",
    "        self.max_features = max_features\n",
    "        self.max_samples = max_samples\n",
    "        self.random_state = random_state\n",
    "        self.learning_rate = learning_rate  # Может быть числом или функцией\n",
    "        self.reg = reg  # Регуляризация\n",
    "        # Важность фичей\n",
    "        self.fi = {}  # Словарь для хранения важности признаков\n",
    "\n",
    "    def __str__(self):\n",
    "        params = vars(self)  # Получаем все атрибуты экземпляра как словарь\n",
    "        params_str = ', '.join(f\"{key}={value}\" for key, value in params.items())\n",
    "        return f\"MyForestReg class: {params_str}\"\n",
    "    \n",
    "    # Метод для расчёта функции потерь\n",
    "    def _calculate_loss(self, y_true, y_pred):\n",
    "        if self.loss == \"MSE\":\n",
    "            return np.mean((y_true - y_pred) ** 2)\n",
    "        elif self.loss == \"MAE\":\n",
    "            return np.mean(np.abs(y_true - y_pred))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid loss function. Supported: 'MSE', 'MAE'.\")\n",
    "        \n",
    "    # Расчет метрик\n",
    "    def _calculate_metric(self, y_true, y_pred):\n",
    "        if self.metric == \"MSE\":\n",
    "            return np.mean((y_true - y_pred) ** 2)\n",
    "        elif self.metric == \"MAE\":\n",
    "            return np.mean(np.abs(y_true - y_pred))\n",
    "        elif self.metric == \"RMSE\":\n",
    "            return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "        elif self.metric == \"R2\":\n",
    "            ss_total = np.sum((y_true - y_true.mean()) ** 2)\n",
    "            ss_residual = np.sum((y_true - y_pred) ** 2)\n",
    "            return 1 - (ss_residual / ss_total)\n",
    "        elif self.metric == \"MAPE\":\n",
    "            return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "        else:\n",
    "            raise ValueError(\"Invalid metric specified.\")\n",
    "    \n",
    "  # Метод fit\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, X_eval=None, y_eval=None, early_stopping=None, verbose=None):\n",
    "        # Фиксируем сид\n",
    "        random.seed(self.random_state)\n",
    "        \n",
    "        self.pred_0 = y.mean()\n",
    "        current_prediction = np.full(y.shape, self.pred_0)\n",
    "        \n",
    "         # Инициализируем важность признаков\n",
    "        self.fi = {col: 0.0 for col in X.columns}\n",
    "\n",
    "        init_cols = list(X.columns)  # Все признаки\n",
    "        init_rows_cnt = X.shape[0]  # Общее число строк\n",
    "        \n",
    "        # добавляем параметры отслеживания остановки\n",
    "        best_score = None\n",
    "        best_iter = 0\n",
    "\n",
    "        for i in range(1, self.n_estimators + 1): # Нумерация итераций от 1 до n_estimators\n",
    "            # Вычисляем learning_rate для текущего шага\n",
    "            if callable(self.learning_rate):\n",
    "                lr = self.learning_rate(i)\n",
    "            else:\n",
    "                lr = self.learning_rate\n",
    "            \n",
    "            # Случайный выбор признаков и строк\n",
    "            cols_smpl_cnt = max(1, round(self.max_features * len(init_cols)))\n",
    "            rows_smpl_cnt = max(1, round(self.max_samples * init_rows_cnt))\n",
    "\n",
    "            cols_idx = random.sample(init_cols, cols_smpl_cnt)\n",
    "            rows_idx = random.sample(range(init_rows_cnt), rows_smpl_cnt)\n",
    "\n",
    "            X_sample = X.iloc[rows_idx][cols_idx]\n",
    "            y_sample = y.iloc[rows_idx]\n",
    "\n",
    "            # Остатки\n",
    "            residual = y_sample - current_prediction[rows_idx]\n",
    "\n",
    "            # Обучение дерева на подвыборке\n",
    "            tree = self._build_tree(X_sample, residual)\n",
    "            num_leaves = tree.get_total_leafs()  # Количество листьев в дереве\n",
    "            self.trees.append((tree, cols_idx, lr, num_leaves))  # Сохраняем дерево, признаки, lr, листья\n",
    "\n",
    "            # Регуляризация: добавляем вклад деревьев, умноженный на reg\n",
    "            regularization_term = self.reg * sum(leaf_count for _, _, _, leaf_count in self.trees)\n",
    "\n",
    "            # Обновление предсказаний с учетом регуляризации\n",
    "            current_prediction[rows_idx] += lr * tree.predict(X_sample) + regularization_term\n",
    "            \n",
    "             # Суммируем важность признаков\n",
    "            feature_importance = tree.feature_importances()\n",
    "            for feature, importance in feature_importance.items():\n",
    "                self.fi[feature] += importance\n",
    "\n",
    "            # Вывод метрик\n",
    "            if verbose and i % verbose == 0:\n",
    "                loss_value = self._calculate_loss(y, current_prediction)\n",
    "                print(f\"{i}. Loss[{self.loss}]: {loss_value:.2f}\")\n",
    "                \n",
    "            # Ранняя остановка\n",
    "            if X_eval is not None and y_eval is not None and early_stopping is not None:\n",
    "                eval_pred = self.predict(X_eval)\n",
    "                score = self._calculate_metric(y_eval, eval_pred)\n",
    "\n",
    "                # Если это первый запуск или метрика улучшилась\n",
    "                if best_score is None or score < best_score:\n",
    "                    best_score = score\n",
    "                    best_iter = i\n",
    "                else:\n",
    "                    # Если метрика не улучшилась за early_stopping итераций, остановим\n",
    "                    if i - best_iter >= early_stopping:\n",
    "                        print(f\"Early stopping at iteration {i} with best score: {best_score:.4f}\")\n",
    "                        break\n",
    "\n",
    "        # После завершения обучения сохраняем финальное значение метрики, если задана\n",
    "        if self.metric:\n",
    "            self.best_score = self._calculate_metric(y, current_prediction)\n",
    "        else:\n",
    "            self.best_score = self._calculate_loss(y, current_prediction)\n",
    "                \n",
    "    def _build_tree(self, X: pd.DataFrame, residual: pd.Series):\n",
    "        # Создание экземпляра дерева регрессии\n",
    "        tree = MyForestReg(\n",
    "            max_depth=self.max_depth,\n",
    "            min_samples_split=self.min_samples_split,\n",
    "            max_leafs=self.max_leafs,\n",
    "            bins=self.bins\n",
    "        )\n",
    "        # Обучение дерева на остатках\n",
    "        tree.fit(X, residual)\n",
    "        return tree\n",
    "\n",
    "    # Метод для подсчета общего числа листьев\n",
    "    def get_total_leafs(self):\n",
    "        # Суммируем количество листьев для каждого дерева в лесу\n",
    "        return sum(tree.get_total_leafs() for tree in self.trees)\n",
    "    \n",
    "    def feature_importances(self):\n",
    "        # Метод для получения важности признаков\n",
    "        return self.fi\n",
    "    \n",
    "     # Метод предсказания\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        # Начальное предсказание\n",
    "        total_prediction = np.full(X.shape[0], self.pred_0)  # Массив с начальным предсказанием для всех строк\n",
    "\n",
    "        for i, (tree, cols, lr, _) in enumerate(self.trees, start=1):  # Добавлен `_` для пропуска количества листьев\n",
    "            # Если learning_rate был функцией, пересчитаем для текущей итерации\n",
    "            if callable(self.learning_rate):\n",
    "                lr = self.learning_rate(i)\n",
    "            # Регуляризация при предсказании\n",
    "            regularization_term = self.reg * sum(leaf_count for _, _, _, leaf_count in self.trees[:i])\n",
    "            total_prediction += lr * tree.predict(X[cols]) + regularization_term\n",
    "        return total_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at iteration 7 with best score: 14701.4875\n",
      "Best score on evaluation set: 18368.6183\n"
     ]
    }
   ],
   "source": [
    "#Тест остановки\n",
    "X, y = make_regression(n_samples=50, n_features=5, noise=0.1, random_state=42)\n",
    "X = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(5)])\n",
    "y = pd.Series(y)\n",
    "\n",
    "# Обучение модели с ранней остановкой\n",
    "model = MyBoostReg(\n",
    "    n_estimators=50, \n",
    "    learning_rate=0.1, \n",
    "    max_depth=3, \n",
    "    reg=0.1, \n",
    "    metric=\"MSE\"  # Используем метрику \"MSE\", определённую в классе\n",
    ")\n",
    "\n",
    "# Обучение с использованием всего набора данных для валидации\n",
    "model.fit(X, y, X_eval=X, y_eval=y, early_stopping=5)\n",
    "\n",
    "# Предсказание\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Вывод результата\n",
    "print(f\"Best score on evaluation set: {model.best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "feature_0: 19021.6635\n",
      "feature_1: 0.0000\n",
      "feature_2: 314094.7646\n",
      "feature_3: 95588.6914\n",
      "feature_4: 18397.4976\n"
     ]
    }
   ],
   "source": [
    "# Тест важности фичей\n",
    "X, y = make_regression(n_samples=20, n_features=5, noise=0.1, random_state=42)\n",
    "X = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(5)])\n",
    "y = pd.Series(y)  # Преобразуем y в Series\n",
    "\n",
    "# Обучение модели\n",
    "model = MyBoostReg(n_estimators=10, learning_rate=0.1, max_depth=3, reg=0.1)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Вывод важности признаков\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in model.feature_importances().items():\n",
    "    print(f\"{feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with reg=0.0\n",
      "Best score with reg=0.0: 0.1612\n",
      "\n",
      "Testing with reg=0.1\n",
      "Best score with reg=0.1: 0.1479\n",
      "\n",
      "Testing with reg=0.5\n",
      "Best score with reg=0.5: -0.0569\n"
     ]
    }
   ],
   "source": [
    "#Тест регуляризации\n",
    "X, y = make_regression(n_samples=20, n_features=10, noise=0.1, random_state=42)\n",
    "X = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "y = pd.Series(y)\n",
    "\n",
    "# Тестируем с разными значениями reg\n",
    "for reg_value in [0.0, 0.1, 0.5]:\n",
    "    print(f\"\\nTesting with reg={reg_value}\")\n",
    "    model = MyBoostReg(\n",
    "        n_estimators=5, \n",
    "        learning_rate=0.1, \n",
    "        max_depth=3, \n",
    "        loss=\"MSE\", \n",
    "        metric=\"R2\", \n",
    "        reg=reg_value\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    print(f\"Best score with reg={reg_value}: {model.best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions (static LR): -680.1626942137246\n",
      "Predictions (dynamic LR): -531.8174657234895\n",
      "Predictions (dynamic LR): -531.8174657234895\n"
     ]
    }
   ],
   "source": [
    "# тест динамического learning rate\n",
    "X, y = make_regression(n_samples=20, n_features=10, noise=0.1, random_state=42)\n",
    "X = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "y = pd.Series(y)\n",
    "\n",
    "# Learning rate как число\n",
    "model_static_lr = MyBoostReg(n_estimators=5, learning_rate=0.1, max_depth=3, loss=\"MSE\", metric=\"R2\")\n",
    "model_static_lr.fit(X, y)\n",
    "print(\"Predictions (static LR):\", model_static_lr.predict(X).sum())\n",
    "\n",
    "# Learning rate как функция\n",
    "dynamic_lr = lambda iter: 0.5 * (0.85 ** iter)\n",
    "model_dynamic_lr1 = MyBoostReg(n_estimators=5, learning_rate=dynamic_lr, max_depth=3, loss=\"MSE\", metric=\"R2\")\n",
    "model_dynamic_lr1.fit(X, y)\n",
    "print(\"Predictions (dynamic LR):\", model_dynamic_lr1.predict(X).sum())\n",
    "\n",
    "model_dynamic_lr2 = MyBoostReg(n_estimators=5, learning_rate=dynamic_lr, max_depth=2, loss=\"MSE\", metric=\"MAPE\")\n",
    "model_dynamic_lr2.fit(X, y)\n",
    "print(\"Predictions (dynamic LR):\", model_dynamic_lr2.predict(X).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R2: 0.16\n",
      "Best RMSE: 185.53\n"
     ]
    }
   ],
   "source": [
    "# Тест стохастического градиентного бустинга\n",
    "X, y = make_regression(n_samples=20, n_features=10, noise=0.1, random_state=42)\n",
    "X = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "y = pd.Series(y)\n",
    "\n",
    "# Тест модели с метрикой R2\n",
    "model_with_r2 = MyBoostReg(n_estimators=5, learning_rate=0.1, max_depth=3, loss=\"MSE\", metric=\"R2\")\n",
    "model_with_r2.fit(X, y)  # Без промежуточного лога\n",
    "print(f\"Best {model_with_r2.metric}: {model_with_r2.best_score:.2f}\")\n",
    "\n",
    "# Тест модели с метрикой RMSE\n",
    "model_with_RMSE = MyBoostReg(n_estimators=5, learning_rate=0.1, max_depth=3, loss=\"MSE\", metric=\"RMSE\")\n",
    "model_with_RMSE.fit(X, y)  # Без промежуточного лога\n",
    "print(f\"Best {model_with_RMSE.metric}: {model_with_RMSE.best_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R2: 0.38\n",
      "Best RMSE: 160.03\n"
     ]
    }
   ],
   "source": [
    "# Тест метрик\n",
    "X, y = make_regression(n_samples=20, n_features=10, noise=0.1, random_state=42)\n",
    "X = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "y = pd.Series(y)\n",
    "\n",
    "# Тест модели с метрикой R2\n",
    "model_with_r2 = MyBoostReg(n_estimators=5, learning_rate=0.1, max_depth=3, loss=\"MSE\", metric=\"R2\")\n",
    "model_with_r2.fit(X, y)  # Без промежуточного лога\n",
    "print(f\"Best {model_with_r2.metric}: {model_with_r2.best_score:.2f}\")\n",
    "\n",
    "# Тест модели с метрикой RMSE\n",
    "model_with_RMSE = MyBoostReg(n_estimators=5, learning_rate=0.1, max_depth=3, loss=\"MSE\", metric=\"RMSE\")\n",
    "model_with_RMSE.fit(X, y)  # Без промежуточного лога\n",
    "print(f\"Best {model_with_RMSE.metric}: {model_with_RMSE.best_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Loss[MSE]: 41038.85\n",
      "2. Loss[MSE]: 33821.36\n",
      "4. Loss[MSE]: 28105.41\n",
      "6. Loss[MSE]: 23413.61\n",
      "8. Loss[MSE]: 19901.45\n",
      "10. Loss[MSE]: 17161.91\n",
      "0. Loss[MAE]: 158.01\n",
      "3. Loss[MAE]: 157.87\n",
      "6. Loss[MAE]: 157.73\n"
     ]
    }
   ],
   "source": [
    "# Тест градиента\n",
    "X, y = make_regression(n_samples=20, n_features=10, noise=0.1, random_state=42)\n",
    "X = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "y = pd.Series(y)\n",
    "\n",
    "# Создаем модели\n",
    "model1 = MyBoostReg(n_estimators=10, learning_rate=0.1, max_depth=3, loss=\"MSE\")\n",
    "model2 = MyBoostReg(n_estimators=8, learning_rate=0.1, max_depth=3, loss=\"MAE\")\n",
    "\n",
    "# Обучаем модель с verbose=2\n",
    "model1.fit(X, y, verbose=2)\n",
    "model2.fit(X, y, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Тестирование на первом наборе данных:\n",
      "Сумма предсказаний для первого набора данных: 414.24\n",
      "\n",
      "Тестирование на втором наборе данных:\n",
      "Сумма предсказаний для второго набора данных: -103.45\n"
     ]
    }
   ],
   "source": [
    "#Тестирование предсказания\n",
    "# Создаем первый небольшой набор данных\n",
    "X1, y1 = make_regression(n_samples=20, n_features=5, noise=0.1, random_state=0)\n",
    "X1 = pd.DataFrame(X1, columns=[f\"feature_{i}\" for i in range(X1.shape[1])])\n",
    "y1 = pd.Series(y1)\n",
    "\n",
    "# Создаем второй небольшой набор данных\n",
    "X2, y2 = make_regression(n_samples=15, n_features=5, noise=0.2, random_state=1)\n",
    "X2 = pd.DataFrame(X2, columns=[f\"feature_{i}\" for i in range(X2.shape[1])])\n",
    "y2 = pd.Series(y2)\n",
    "\n",
    "# Параметры модели\n",
    "params = {\n",
    "    'n_estimators': 5,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'min_samples_split': 2,\n",
    "    'max_leafs': 5,\n",
    "    'bins': None\n",
    "}\n",
    "\n",
    "# Создаем модель\n",
    "model = MyBoostReg(**params)\n",
    "\n",
    "# Тестирование на первом наборе данных\n",
    "print(\"\\nТестирование на первом наборе данных:\")\n",
    "model.fit(X1, y1)  # Обучаем модель\n",
    "predictions1 = model.predict(X1)  # Делаем предсказания\n",
    "total_prediction1 = predictions1.sum()  # Сумма предсказаний\n",
    "print(f\"Сумма предсказаний для первого набора данных: {total_prediction1:.2f}\")\n",
    "\n",
    "# Тестирование на втором наборе данных\n",
    "print(\"\\nТестирование на втором наборе данных:\")\n",
    "model.fit(X2, y2)  # Обучаем модель\n",
    "predictions2 = model.predict(X2)  # Делаем предсказания\n",
    "total_prediction2 = predictions2.sum()  # Сумма предсказаний\n",
    "print(f\"Сумма предсказаний для второго набора данных: {total_prediction2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Тестирование с параметрами: {'n_estimators': 3, 'learning_rate': 0.1, 'max_depth': 5, 'min_samples_split': 2, 'max_leafs': 10, 'bins': 16}\n",
      "pred_0: 23.30\n",
      "Общее количество листьев: 362\n",
      "\n",
      "Тестирование с параметрами: {'n_estimators': 5, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_split': 3, 'max_leafs': 12, 'bins': None}\n",
      "pred_0: 23.30\n",
      "Общее количество листьев: 724\n",
      "\n",
      "Тестирование с параметрами: {'n_estimators': 7, 'learning_rate': 0.01, 'max_depth': 8, 'min_samples_split': 4, 'max_leafs': 15, 'bins': 8}\n",
      "pred_0: 23.30\n",
      "Общее количество листьев: 1169\n"
     ]
    }
   ],
   "source": [
    "# Тест обучения\n",
    "X, y = make_regression(n_samples=200, n_features=10, noise=0.1, random_state=42)\n",
    "X = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "y = pd.Series(y)\n",
    "\n",
    "# Параметры для тестирования\n",
    "test_params = [\n",
    "    {\"n_estimators\": 3, \"learning_rate\": 0.1, \"max_depth\": 5, \"min_samples_split\": 2, \"max_leafs\": 10, \"bins\": 16},\n",
    "    {\"n_estimators\": 5, \"learning_rate\": 0.05, \"max_depth\": 6, \"min_samples_split\": 3, \"max_leafs\": 12, \"bins\": None},\n",
    "    {\"n_estimators\": 7, \"learning_rate\": 0.01, \"max_depth\": 8, \"min_samples_split\": 4, \"max_leafs\": 15, \"bins\": 8},\n",
    "]\n",
    "\n",
    "# Функция для подсчёта общего числа листьев во всех деревьях\n",
    "def count_total_leaves(model):\n",
    "    # Суммируем количество листьев всех деревьев в модели\n",
    "    return sum(tree.get_total_leafs() for tree in model.trees)\n",
    "\n",
    "# Тестирование\n",
    "for params in test_params:\n",
    "    print(f\"\\nТестирование с параметрами: {params}\")\n",
    "    \n",
    "    # Создаём модель с текущими параметрами\n",
    "    model = MyBoostReg(**params)\n",
    "    \n",
    "    # Обучаем модель\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Вывод результата\n",
    "    print(f\"pred_0: {model.pred_0:.2f}\")\n",
    "    total_leaves = count_total_leaves(model)  # Подсчитываем количество листьев\n",
    "    print(f\"Общее количество листьев: {total_leaves}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyForestReg class: n_estimators=10, learning_rate=0.1, max_depth=5, min_samples_split=2, max_leafs=20, bins=None, pred_0=None, trees=[]\n",
      "MyForestReg class: n_estimators=10, learning_rate=0.1, max_depth=5, min_samples_split=5, max_leafs=10, bins=6, pred_0=None, trees=[]\n",
      "MyForestReg class: n_estimators=8, learning_rate=0.1, max_depth=5, min_samples_split=5, max_leafs=20, bins=16, pred_0=None, trees=[]\n"
     ]
    }
   ],
   "source": [
    "# Тестирование класса\n",
    "model1 = MyBoostReg()\n",
    "model2 = MyBoostReg(n_estimators=10,  max_depth=5, min_samples_split=5, max_leafs=10, bins=6)\n",
    "model3 = MyBoostReg(n_estimators=8, max_depth=5, min_samples_split=5, max_leafs=20, bins=16)\n",
    "\n",
    "# Проверка\n",
    "print(model1)\n",
    "print(model2)\n",
    "print(model3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
