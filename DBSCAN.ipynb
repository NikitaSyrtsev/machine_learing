{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDBSCAN:\n",
    "    def __init__(self, eps=3, min_samples=3, metric='euclidian'):\n",
    "        # Инициализация параметров eps и min_samples\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "        self.metric = metric\n",
    "        \n",
    "    def __str__(self):\n",
    "        # Формируем строку с параметрами экземпляра\n",
    "        params = vars(self)\n",
    "        params_str = ', '.join(f\"{key}={value}\" for key, value in params.items())\n",
    "        return f\"MyDBSCAN class: {params_str}\"\n",
    "    \n",
    "    def fit_predict(self, X):\n",
    "        # Проверка, что X является DataFrame\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "\n",
    "        # Количество точек в датасете\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # Массив для меток кластеров\n",
    "        labels = -1 * np.ones(n_samples, dtype=int)  # -1 означает шум\n",
    "\n",
    "        # Массив для пометки точек как посещенных\n",
    "        visited = np.zeros(n_samples, dtype=bool)\n",
    "\n",
    "        cluster_id = 0\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            if visited[i]:\n",
    "                continue\n",
    "\n",
    "            visited[i] = True\n",
    "            neighbors = self._region_query(X, i)\n",
    "\n",
    "            # Если соседей меньше, чем min_samples, метим точку как шум\n",
    "            if len(neighbors) < self.min_samples:\n",
    "                continue\n",
    "\n",
    "            # Рекурсивное расширение кластера\n",
    "            self._expand_cluster(X, labels, i, neighbors, cluster_id, visited)\n",
    "\n",
    "            cluster_id += 1\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def _region_query(self, X, point_idx):\n",
    "        #Нахождение соседей точки в пределах eps с использованием выбранной метрики\n",
    "        distances = self._compute_distance(X, point_idx)\n",
    "        neighbors = np.where(distances <= self.eps)[0]\n",
    "        return neighbors\n",
    "\n",
    "    def _compute_distance(self, X, point_idx):\n",
    "        #Вычисление расстояний в зависимости от выбранной метрики\n",
    "        if self.metric == 'euclidean':\n",
    "            return np.linalg.norm(X.values - X.iloc[point_idx].values, axis=1)\n",
    "        elif self.metric == 'chebyshev':\n",
    "            return np.max(np.abs(X.values - X.iloc[point_idx].values), axis=1)\n",
    "        elif self.metric == 'manhattan':\n",
    "            return np.sum(np.abs(X.values - X.iloc[point_idx].values), axis=1)\n",
    "        elif self.metric == 'cosine':\n",
    "            return 1 - cosine_similarity(X.iloc[point_idx:point_idx+1].values, X.values).flatten()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric: {self.metric}\")\n",
    "\n",
    "    def _expand_cluster(self, X, labels, point_idx, neighbors, cluster_id, visited):\n",
    "        #Рекурсивное добавление точек в кластер\n",
    "        labels[point_idx] = cluster_id\n",
    "\n",
    "        i = 0\n",
    "        while i < len(neighbors):\n",
    "            current_idx = neighbors[i]\n",
    "            \n",
    "            if not visited[current_idx]:\n",
    "                visited[current_idx] = True\n",
    "                new_neighbors = self._region_query(X, current_idx)\n",
    "\n",
    "                # Если точка имеет достаточно соседей, добавляем её в кластер\n",
    "                if len(new_neighbors) >= self.min_samples:\n",
    "                    neighbors = np.concatenate((neighbors, new_neighbors))\n",
    "\n",
    "            if labels[current_idx] == -1:  # Если точка еще не помечена, помечаем её\n",
    "                labels[current_idx] = cluster_id\n",
    "\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метки кластеров (Евклидово): [ 0  0  0 -1  1  2  0  1  1  1 -1 -1  2  0  2 -1  2  2  1 -1]\n",
      "Метки кластеров (Манхэттенское): [ 0  0  0 -1 -1 -1  0 -1 -1 -1 -1 -1 -1  0 -1 -1 -1 -1 -1 -1]\n",
      "Метки кластеров (Косинусное): [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Метки кластеров (Чебышёв): [ 0  0  0  0  1  2  0  1  1  1 -1  1  2  0  2 -1  2  2  1  1]\n"
     ]
    }
   ],
   "source": [
    "#Тест метрик\n",
    "X, y = make_blobs(n_samples=20, centers=3, random_state=42)\n",
    "\n",
    "# Преобразуем в DataFrame для удобства\n",
    "X_df = pd.DataFrame(X, columns=['Feature 1', 'Feature 2'])\n",
    "\n",
    "# Пример 1: Используем Евклидово расстояние\n",
    "dbscan_euclidean = MyDBSCAN(eps=1.5, min_samples=5, metric='euclidean')\n",
    "labels_euclidean = dbscan_euclidean.fit_predict(X_df)\n",
    "print(f\"Метки кластеров (Евклидово): {labels_euclidean}\")\n",
    "\n",
    "# Пример 2: Используем Манхэттенское расстояние\n",
    "dbscan_manhattan = MyDBSCAN(eps=1.5, min_samples=5, metric='manhattan')\n",
    "labels_manhattan = dbscan_manhattan.fit_predict(X_df)\n",
    "print(f\"Метки кластеров (Манхэттенское): {labels_manhattan}\")\n",
    "\n",
    "# Пример 3: Используем Косинусное расстояние\n",
    "dbscan_cosine = MyDBSCAN(eps=1.5, min_samples=5, metric='cosine')\n",
    "labels_cosine = dbscan_cosine.fit_predict(X_df)\n",
    "print(f\"Метки кластеров (Косинусное): {labels_cosine}\")\n",
    "\n",
    "# Пример 4: Используем Расстояние Чебышёва\n",
    "dbscan_chebyshev = MyDBSCAN(eps=1.5, min_samples=5, metric='chebyshev')\n",
    "labels_chebyshev = dbscan_chebyshev.fit_predict(X_df)\n",
    "print(f\"Метки кластеров (Чебышёв): {labels_chebyshev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 -1  1  2  0  1  1  1 -1 -1  2  0  2 -1  2  2  1 -1]\n"
     ]
    }
   ],
   "source": [
    "# Тест обучения-предсказания\n",
    "X, y = make_blobs(n_samples=20, centers=3, random_state=42)\n",
    "\n",
    "# Преобразуем в DataFrame для удобства\n",
    "X_df = pd.DataFrame(X, columns=['Feature 1', 'Feature 2'])\n",
    "\n",
    "# Создаем экземпляр класса DBSCAN\n",
    "dbscan = MyDBSCAN(eps=1.5, min_samples=5)\n",
    "\n",
    "# Выполняем кластеризацию\n",
    "labels = dbscan.fit_predict(X_df)\n",
    "\n",
    "# Печатаем метки кластеров для каждой точки\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyKMeans class: eps=3, min_samples=3\n",
      "MyKMeans class: eps=5, min_samples=4\n",
      "MyKMeans class: eps=4, min_samples=3\n"
     ]
    }
   ],
   "source": [
    "# Тест класса\n",
    "model1 = MyDBSCAN()\n",
    "print(model1)\n",
    "\n",
    "model2 = MyDBSCAN(eps=5, min_samples=4)\n",
    "print(model2)\n",
    "\n",
    "model3 = MyDBSCAN(eps=4)\n",
    "print(model3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
