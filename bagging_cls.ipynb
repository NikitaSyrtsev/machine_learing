{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "\n",
    "# импортируем мои классы\n",
    "from TreeCls import MyTreeClf\n",
    "from LogReg import MyLogReg\n",
    "from KNNcls import MyKNNClf\n",
    "\n",
    "# импортируем метрики для OOB error\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBaggingClf:\n",
    "    def __init__(self, estimator=None, n_estimators=10, max_samples=1.0, random_state=42, oob_score=None):\n",
    "        self.estimator = estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.random_state = random_state\n",
    "        self.oob_score = oob_score  # Тип метрики для OOB оценки\n",
    "        self.oob_score_ = None  # Хранение OOB метрики после обучения\n",
    "        \n",
    "    def __str__(self):\n",
    "        params = vars(self) # Получаем все атрибуты экземпляра как словарь\n",
    "        params_str = ', '.join(f\"{key}={value}\" for key, value in params.items())\n",
    "        return f\"MyTreeClf class: {params_str}\"\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        #Обучаем ансамбль моделей на бутстреп-выборках данных\n",
    "        random.seed(self.random_state)  # Фиксируем сид для воспроизводимости бутстреп-выборок\n",
    "        n_samples = X.shape[0]  # Количество строк в обучающей выборке\n",
    "        rows_num_list = list(range(n_samples))\n",
    "        rows_smpl_cnt = int(n_samples * self.max_samples)  # Количество строк для каждой бутстреп-выборки\n",
    "        \n",
    "        # Список для хранения OOB предсказаний и счетчик количества предсказаний для каждого образца\n",
    "        oob_predictions = np.zeros(n_samples)\n",
    "        oob_counts = np.zeros(n_samples)  # Считает, сколько раз каждый образец попал в OOB\n",
    "        \n",
    "        # Очищаем список моделей\n",
    "        self.estimators = []\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            # Генерируем индексы для бутстреп-выборки\n",
    "            sample_rows_idx = random.choices(rows_num_list, k=rows_smpl_cnt)\n",
    "            oob_rows_idx = list(set(rows_num_list) - set(sample_rows_idx))  # Индексы OOB-выборки\n",
    "\n",
    "            # Создаем подвыборку для текущего базового классификатора\n",
    "            X_sample = X.iloc[sample_rows_idx]\n",
    "            y_sample = y.iloc[sample_rows_idx]\n",
    "\n",
    "            # Копируем базовую модель и обучаем её на бутстреп-выборке\n",
    "            model = deepcopy(self.estimator)\n",
    "            model.fit(X_sample, y_sample)\n",
    "\n",
    "            # Сохраняем обученную модель\n",
    "            self.estimators.append(model)\n",
    "            \n",
    "            # Предсказания для OOB-выборки\n",
    "            if oob_rows_idx:\n",
    "                oob_pred_proba = model.predict_proba(X.iloc[oob_rows_idx])\n",
    "                oob_predictions[oob_rows_idx] += oob_pred_proba  # Накопление вероятностей для усреднения\n",
    "                oob_counts[oob_rows_idx] += 1  # Учет количества предсказаний для каждого OOB образца\n",
    "\n",
    "        # Усреднение вероятностей по каждому OOB экземпляру\n",
    "        oob_avg_predictions = np.divide(oob_predictions, oob_counts, where=oob_counts > 0)\n",
    "        oob_pred_labels = (oob_avg_predictions > 0.5).astype(int)  # Перевод в метки по порогу 0.5\n",
    "\n",
    "        # Выбор метрики для расчета oob_score_\n",
    "        if self.oob_score == 'accuracy':\n",
    "            self.oob_score_ = accuracy_score(y, oob_pred_labels)\n",
    "        elif self.oob_score == 'precision':\n",
    "            self.oob_score_ = precision_score(y, oob_pred_labels)\n",
    "        elif self.oob_score == 'recall':\n",
    "            self.oob_score_ = recall_score(y, oob_pred_labels)\n",
    "        elif self.oob_score == 'f1':\n",
    "            self.oob_score_ = f1_score(y, oob_pred_labels)\n",
    "        elif self.oob_score == 'roc_auc':\n",
    "            self.oob_score_ = roc_auc_score(y, oob_avg_predictions)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, type='mean'):\n",
    "        #Возвращает предсказанные классы для набора данных X.\n",
    "        all_predictions = []\n",
    "        \n",
    "        # Собираем вероятности от каждой модели для всех строк X\n",
    "        for estimator in self.estimators:\n",
    "            all_predictions.append(estimator.predict_proba(X))\n",
    "        \n",
    "        # Преобразуем список вероятностей в массив (кол-во моделей x кол-во строк в X)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        \n",
    "        if type == 'mean':\n",
    "            # Усредняем вероятности по всем моделям и переводим в классы по порогу > 0.5\n",
    "            avg_proba = np.mean(all_predictions, axis=0)\n",
    "            return (avg_proba > 0.5).astype(int).tolist()\n",
    "        \n",
    "        elif type == 'vote':\n",
    "            # Переводим вероятности в классы для каждой модели\n",
    "            all_classes = (all_predictions > 0.5).astype(int)\n",
    "            \n",
    "            # Для каждого примера выбираем наиболее частый класс, если одинаково - возвращаем 1\n",
    "            final_classes = []\n",
    "            for i in range(X.shape[0]):\n",
    "                votes = all_classes[:, i]\n",
    "                most_common = Counter(votes).most_common()\n",
    "                # Проверяем, если классы 0 и 1 встречаются одинаково, возвращаем 1, иначе возвращаем наиболее частый\n",
    "                if len(most_common) > 1 and most_common[0][1] == most_common[1][1]:\n",
    "                    final_classes.append(1)\n",
    "                else:\n",
    "                    final_classes.append(most_common[0][0])\n",
    "            return final_classes\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        #Возвращает вероятности для класса 1 для каждой строки в X.\n",
    "        all_probabilities = []\n",
    "        \n",
    "        # Собираем вероятности от каждой модели для всех строк X\n",
    "        for estimator in self.estimators:\n",
    "            all_probabilities.append(estimator.predict_proba(X))\n",
    "        \n",
    "        # Усредняем вероятности по всем моделям\n",
    "        avg_proba = np.mean(all_probabilities, axis=0)\n",
    "        return avg_proba.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB score (accuracy): 0.54\n",
      "OOB score (precision): 0.40625\n",
      "OOB score (recall): 0.325\n"
     ]
    }
   ],
   "source": [
    "# тестирование метрик OOB\n",
    "# Генерация случайных данных\n",
    "np.random.seed(42)\n",
    "X_test = pd.DataFrame(np.random.rand(100, 5))  # 100 образцов, 5 фичей\n",
    "y_test = pd.Series(np.random.randint(0, 2, 100))  # 100 бинарных меток (0 или 1)\n",
    "\n",
    "# Используем ваш класс KNN в качестве базового классификатора\n",
    "knn_model = MyKNNClf(k=3, metric='euclidean', weight='uniform')\n",
    "\n",
    "# Функция для тестирования MyBaggingClf с разными метриками OOB\n",
    "def test_oob_score(metric_name):\n",
    "    bagging_clf = MyBaggingClf(estimator=deepcopy(knn_model), n_estimators=10, max_samples=0.8, oob_score=metric_name, random_state=42)\n",
    "    bagging_clf.fit(X_test, y_test)\n",
    "    print(f\"OOB score ({metric_name}):\", bagging_clf.oob_score_)\n",
    "\n",
    "# Тестирование для трех метрик: accuracy, precision, recall\n",
    "for metric in ['accuracy', 'precision', 'recall']:\n",
    "    test_oob_score(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тест 1 - Mean averaging\n",
      "Predicted classes with 'mean': [0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1]\n",
      "\n",
      "Тест 2 - Voting averaging\n",
      "Predicted classes with 'vote': [0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Тестирование предсказания\n",
    "# Создаем данные для тестирования\n",
    "X, y = make_classification(n_samples=100, n_features=5, random_state=42)\n",
    "X = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "y = pd.Series(y)\n",
    "\n",
    "# Инициализируем базовую модель KNN\n",
    "base_model = MyKNNClf(k=3)\n",
    "\n",
    "# Инициализируем Bagging с базовой моделью\n",
    "bagging_clf = MyBaggingClf(estimator=base_model, n_estimators=10, max_samples=0.8, random_state=42)\n",
    "bagging_clf.fit(X, y)\n",
    "\n",
    "# Тест 1: Предсказание с типом усреднения \"mean\"\n",
    "mean_predictions = bagging_clf.predict(X, type='mean')\n",
    "print(\"Тест 1 - Mean averaging\")\n",
    "print(\"Predicted classes with 'mean':\", mean_predictions)\n",
    "\n",
    "# Тест 2: Предсказание с типом усреднения \"vote\"\n",
    "vote_predictions = bagging_clf.predict(X, type='vote')\n",
    "print(\"\\nТест 2 - Voting averaging\")\n",
    "print(\"Predicted classes with 'vote':\", vote_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя сумма предсказаний для всех моделей: 46.93333333333334\n"
     ]
    }
   ],
   "source": [
    "# Тестирование обучения с KNNClf\n",
    "X, y = make_classification(n_samples=100, n_features=5, n_informative=3, n_redundant=0, random_state=42)\n",
    "X_train = pd.DataFrame(X) \n",
    "y_train = pd.Series(y) \n",
    "\n",
    "# Инициализация и обучение ансамбля с использованием MyKNNClf в качестве базового классификатора\n",
    "bagging_clf = MyBaggingClf(estimator=MyKNNClf(k=3, metric='euclidean', weight='uniform'), \n",
    "                           n_estimators=5, max_samples=0.8, random_state=42)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Подсчет средней суммы предсказаний для всех моделей\n",
    "pred_sums = []\n",
    "for model in bagging_clf.estimators:\n",
    "    model_preds = model.predict_proba(X_train)\n",
    "    pred_sums.append(np.sum(model_preds))\n",
    "\n",
    "average_pred_sum = np.mean(pred_sums)\n",
    "\n",
    "# Вывод средней суммы предсказаний для всех моделей\n",
    "print(\"Средняя сумма предсказаний для всех моделей:\", average_pred_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее количество листьев для всех моделей: 9.4\n"
     ]
    }
   ],
   "source": [
    "# Тестирование обучения с TreeClf\n",
    "# Генерация синтетических данных\n",
    "X, y = make_classification(n_samples=100, n_features=5, n_informative=3, n_redundant=0, random_state=42)\n",
    "X_train = pd.DataFrame(X)\n",
    "y_train = pd.Series(y)   \n",
    "\n",
    "# Инициализация и обучение ансамбля с использованием MyTreeClf в качестве базового классификатора\n",
    "bagging_clf = MyBaggingClf(estimator=MyTreeClf(max_depth=5, min_samples_split=2, max_leafs=20, criterion='entropy'), \n",
    "                           n_estimators=5, max_samples=0.8, random_state=42)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Подсчет среднего количества листьев для всех обученных деревьев\n",
    "leaf_counts = [tree.leaf_count() for tree in bagging_clf.estimators]\n",
    "average_leaf_count = np.mean(leaf_counts)\n",
    "\n",
    "# Вывод средней информации о листьях\n",
    "print(\"Среднее количество листьев для всех моделей:\", average_leaf_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loss: 0.37\n",
      "Start loss: 0.37\n",
      "Start loss: 0.37\n",
      "Start loss: 0.37\n",
      "Start loss: 0.37\n",
      "Сумма весов модели 1: 5.977673983247902\n",
      "Сумма весов модели 2: 5.977673983247902\n",
      "Сумма весов модели 3: 5.977673983247902\n",
      "Сумма весов модели 4: 5.977673983247902\n",
      "Сумма весов модели 5: 5.977673983247902\n"
     ]
    }
   ],
   "source": [
    "# Тестирование обучения с LogLoss\n",
    "# Создаём синтетический набор данных для бинарной классификации\n",
    "X, y = make_classification(n_samples=100, n_features=5, n_informative=3, n_redundant=0, random_state=42)\n",
    "X_train = pd.DataFrame(X) \n",
    "y_train = pd.Series(y)\n",
    "\n",
    "# Инициализируем MyBaggingClf с MyLogReg в качестве базового классификатора\n",
    "bagging_clf = MyBaggingClf(estimator=MyLogReg(n_iter=50, learning_rate=0.01), n_estimators=5, max_samples=0.8, random_state=42)\n",
    "\n",
    "# Обучим модель на тренировочных данных\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Выводим сумму весов для каждой модели в ансамбле\n",
    "for i, model in enumerate(bagging_clf.estimators):\n",
    "    weights_sum = np.sum(model.weights)\n",
    "    print(f\"Сумма весов модели {i + 1}: {weights_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyTreeClf class: estimator=None, n_estimators=10, max_samples=1.0, random_state=42\n",
      "MyTreeClf class: estimator=None, n_estimators=100, max_samples=1.0, random_state=42\n",
      "MyTreeClf class: estimator=None, n_estimators=10, max_samples=0.7, random_state=42\n"
     ]
    }
   ],
   "source": [
    "# Тестирование класса\n",
    "sample1 = MyBaggingClf()\n",
    "sample2 = MyBaggingClf(n_estimators=100)\n",
    "sample3 = MyBaggingClf(max_samples=0.7)\n",
    "\n",
    "# Проверка\n",
    "print(sample1)\n",
    "print(sample2)\n",
    "print(sample3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
